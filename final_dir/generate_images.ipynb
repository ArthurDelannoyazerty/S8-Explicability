{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# A script that generate images in the output folder : non attacked, saliency non attacked, attacked, saliency attacked (with all combinaisons of : models, attacks, effect of attack)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_J17H9FPoiVW"
      },
      "outputs": [],
      "source": [
        "#!pip install tf-keras-vis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "nYcwSbqeorX6",
        "outputId": "42d3c6f9-51fc-421a-bb4f-d03362b8e296"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing : Load libraries\n",
            "Tensorflow recognized 0 GPUs\n"
          ]
        }
      ],
      "source": [
        "print(\"Executing : Load libraries\")\n",
        "\n",
        "import os\n",
        "# uncomment to force the non use of GPU\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tf_keras_vis.utils import num_of_gpus\n",
        "\n",
        "from keras.utils import load_img, img_to_array, array_to_img\n",
        "\n",
        "import foolbox as fb\n",
        "from foolbox.criteria import TargetedMisclassification\n",
        "from foolbox.attacks import PGD\n",
        "\n",
        "from keras.applications.resnet import ResNet50, preprocess_input, decode_predictions\n",
        "\n",
        "from tf_keras_vis.utils.scores import CategoricalScore\n",
        "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
        "from tf_keras_vis.saliency import Saliency\n",
        "\n",
        "from PIL import Image, ImageChops, ImageEnhance\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from scipy.stats import pearsonr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "_, gpus = num_of_gpus()\n",
        "print('Tensorflow recognized {} GPUs'.format(gpus))\n",
        "\n",
        "path_project_root = os.path.dirname(os.path.abspath(''))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YmybNIO7oztN"
      },
      "source": [
        "# SALIENCY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "O1jT7hhgou_o"
      },
      "outputs": [],
      "source": [
        "def load_model(model_name=\"MobileNetV2\"):\n",
        "    \"\"\"\n",
        "        Return the selected model. Argument : name of the model.\n",
        "    \"\"\"\n",
        "    print(\"Executing : Load Model\")\n",
        "    model=\"\"\n",
        "    if model_name==\"VGG16\":\n",
        "        from keras.applications.vgg16 import VGG16 as Model\n",
        "        model = Model(weights='imagenet', include_top=True)\n",
        "    elif model_name==\"MobileNetV2\":\n",
        "        from keras.applications.mobilenet_v2 import MobileNetV2 as Model\n",
        "        model = Model(weights='imagenet', include_top=True)\n",
        "    elif model_name==\"ResNet152V2\":\n",
        "        from keras.applications.resnet_v2 import ResNet152V2 as Model\n",
        "        model = Model(weights='imagenet', include_top=True)\n",
        "    else:\n",
        "        print(\"Error : model not available\")\n",
        "        raise NameError()\n",
        "    return model\n",
        "\n",
        "def get_image(path, size=(224,224), model_name=\"MobileNetV2\"):\n",
        "    print(\"Executing : Load And Preprocess Image\")\n",
        "    image= load_img(path)\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = preprocess_image(image, model_name)\n",
        "    return image\n",
        "\n",
        "def preprocess_image(image, model_name):\n",
        "    if model_name==\"VGG16\":\n",
        "        image = tf.keras.applications.vgg16.preprocess_input(image)\n",
        "    elif model_name==\"MobileNetV2\":\n",
        "        image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
        "    elif model_name==\"ResNet152V2\":\n",
        "        image = tf.keras.applications.resnet_v2.preprocess_input(image)\n",
        "    return image\n",
        "\n",
        "def get_score_function(index_list):\n",
        "    print(\"Executing : Create Score Function\")\n",
        "    return CategoricalScore(index_list)\n",
        "\n",
        "def get_saliency_object(model):\n",
        "    print(\"Executing : Create Saliency Object\")\n",
        "    replace2linear = ReplaceToLinear()\n",
        "    saliency = Saliency(model, model_modifier=replace2linear, clone=True)\n",
        "    return saliency"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ejZM-CzPo_Ok"
      },
      "source": [
        "# ATTACK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fdkXUR9nowpL"
      },
      "outputs": [],
      "source": [
        "def get_attacked_image_FGSM(image, model, image_index, debug = False, attack_rate = 15): #attack_rate entre 0 et 100\n",
        "\n",
        "    pretrained_model = model\n",
        "    pretrained_model.trainable = False\n",
        "\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    image = image[None, ...]\n",
        "  \n",
        "    image_probs = pretrained_model.predict(image)\n",
        "    label = tf.one_hot(image_index, image_probs.shape[-1])\n",
        "    label = tf.reshape(label, (1, image_probs.shape[-1]))\n",
        "    \n",
        "    if debug:\n",
        "      decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions\n",
        "      _, image_class, class_confidence = decode_predictions(image_probs, top=1)[0][0]\n",
        "      plt.imshow(image[0] * 0.5 + 0.5)  # To change [-1, 1] to [0,1]\n",
        "      plt.title('{} : {:.2f}% Confidence'.format(image_class, class_confidence*100))\n",
        "      plt.show()\n",
        "    \n",
        "\n",
        "    loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      tape.watch(image)\n",
        "      prediction = pretrained_model(image)\n",
        "      loss = loss_object(label, prediction)\n",
        "\n",
        "    # Get the gradients of the loss w.r.t to the input image.\n",
        "    gradient = tape.gradient(loss, image)\n",
        "    # Get the sign of the gradients to create the perturbation\n",
        "    signed_grad = tf.sign(gradient)\n",
        "    perturbations = signed_grad\n",
        "    \n",
        "    #for i, eps in enumerate(epsilons):\n",
        "    adv_x = image + (attack_rate/100)*perturbations\n",
        "    adv_x = tf.clip_by_value(adv_x, -1, 1)\n",
        "    \n",
        "    if debug :\n",
        "      plt.imshow(perturbations[0] * 0.5 + 0.5);  # To change [-1, 1] to [0,1]\n",
        "      plt.title(\"Noise\")\n",
        "      plt.show()\n",
        "       #epsilons = [0, 0.01, 0.1, 0.15] #noter \"taux d'attaque\"\n",
        "      descriptions = ['Epsilon = {:0.3f}'.format(attack_rate)]\n",
        "      _, label, confidence = decode_predictions(pretrained_model.predict(adv_x), top=1)[0][0]\n",
        "      plt.imshow(adv_x[0]*0.5+0.5)\n",
        "      plt.title('{} \\n {} : {:.2f}% Confidence'.format(descriptions[0], label, confidence*100))\n",
        "      plt.show()\n",
        "\n",
        "    attacked_image = adv_x[0]\n",
        "    return attacked_image\n",
        "\n",
        "def get_attacked_image_PGD(model, orig_input, debug = False, attack_rate = 10, class_target = 999) : #class_target c'est la classe que l'on cherche à appliquer\n",
        "    orig_input = tf.expand_dims(orig_input, 0)\n",
        "    \n",
        "    fmodel = fb.TensorFlowModel(model, bounds=(-255, 255))\n",
        "   \n",
        "    #goldfish = 1; brown bear = 294; assault rifle = 413 #class de notre image\n",
        "    # 2 = great white shark #classe que l'on cherche à obtenir\n",
        "    adv_label = tf.convert_to_tensor([class_target])\n",
        "\n",
        "    criterion = TargetedMisclassification(adv_label)\n",
        "\n",
        "    attack = PGD()\n",
        "    input_as_tensor = tf.convert_to_tensor(orig_input)\n",
        "    adv_input = attack.run(fmodel, input_as_tensor, criterion, epsilon=attack_rate)\n",
        "    adv_img = (adv_input.numpy() + 255) / 2\n",
        "    adv_img = adv_img.reshape(224, 224, 3)\n",
        "    adv_img = array_to_img(adv_img)\n",
        "    b, g, r = adv_img.split()\n",
        "    adv_img = Image.merge(\"RGB\", (r, g, b))\n",
        "    \n",
        "    if debug :\n",
        "      adv_input = img_to_array(adv_img)\n",
        "      adv_input = adv_input.reshape((1, 224, 224, 3))\n",
        "      adv_input = preprocess_input(adv_input)\n",
        "      predictions = model.predict(adv_input)\n",
        "      labels = decode_predictions(predictions)\n",
        "      kind = labels[0][0][1].replace(\"_\", \" \").title()\n",
        "      percent = round(labels[0][0][2] * 100, 2)\n",
        "      print(f\"This is a {kind}. I am {percent} % sure.\")\n",
        "      print()\n",
        "      print(\"Other suggestions:\")\n",
        "      for i in range(4):\n",
        "        kind = labels[0][i+1][1].replace(\"_\", \" \").title()\n",
        "        percent = round(labels[0][i+1][2] * 100, 2)\n",
        "        print(f\"{kind}: {percent} %\")\n",
        "      difference = ImageChops.difference(adv_img, orig_input)\n",
        "      plt.figure()\n",
        "      plt.imshow(np.array(difference))\n",
        "      plt.show()\n",
        "      difference = ImageEnhance.Brightness(difference).enhance(10)\n",
        "      plt.figure()\n",
        "      plt.imshow(np.array(difference))\n",
        "      plt.show()\n",
        "\n",
        "    return adv_img"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FrLezdjTpESi"
      },
      "source": [
        "# MAIN PROGRAM"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If 1 image is 100Ko => 40Mo generated for each input image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing : Create Score Function\n",
            "Executing : Create Score Function\n",
            "Executing : Create Score Function\n",
            "Executing : Create Score Function\n",
            "Executing : Create Score Function\n",
            "Executing : Create Score Function\n",
            "Executing : Create Score Function\n",
            "Executing : Create Score Function\n"
          ]
        }
      ],
      "source": [
        "models_availables = [\"ResNet152V2\", \"MobileNetV2\", \"VGG16\"]\n",
        "attacks_availables = [\"FGSM\", \"PGD\"]\n",
        "input_directory  = os.path.join(path_project_root, 'final_dir\\images\\input')\n",
        "output_directory = os.path.join(path_project_root, 'final_dir\\images\\output\\\\')\n",
        "index_images_model = [404, 294, 500, 1, 576, 587, 606, 413]\n",
        "epsilons = [0.0, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1.0]\n",
        "\n",
        "score_list = list()\n",
        "for value in index_images_model:\n",
        "    score_list.append(get_score_function([value]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing : Load Model\n",
            "Executing : Create Saliency Object\n",
            "Executing : Load And Preprocess Image\n",
            "Executing : Saliency\n",
            "Executing : Attack FGSM\n",
            "Executing : Saliency on Attacked image\n",
            "Executing : Prediction attacked image\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Executing : Save images\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "Executing : Load And Preprocess Image\n",
            "Executing : Saliency\n",
            "Executing : Attack FGSM\n",
            "Executing : Saliency on Attacked image\n",
            "Executing : Prediction attacked image\n",
            "1/1 [==============================] - 0s 257ms/step\n",
            "1/1 [==============================] - 0s 211ms/step\n",
            "Executing : Save images\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "Executing : Load And Preprocess Image\n",
            "Executing : Saliency\n",
            "Executing : Attack FGSM\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9620\\1255296551.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Executing : Attack \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mattack_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mattacked_image\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mattack_name\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mattacks_availables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                         \u001b[0mattacked_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_attacked_image_PGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattack_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattack_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m                     \u001b[1;32melif\u001b[0m \u001b[0mattack_name\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"FGSM\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                         \u001b[0mattacked_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_attacked_image_FGSM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_images_model\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattack_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattack_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9620\\2232003206.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(model, orig_input, debug, attack_rate, class_target)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTargetedMisclassification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madv_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[0mattack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0minput_as_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0madv_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_as_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattack_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m     \u001b[0madv_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0madv_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0madv_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madv_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0madv_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_to_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madv_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Arthur\\anaconda3\\envs\\saliency\\lib\\site-packages\\foolbox\\attacks\\gradient_descent_base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m             \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mgradient_step_sign\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Arthur\\anaconda3\\envs\\saliency\\lib\\site-packages\\foolbox\\attacks\\gradient_descent_base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, loss_fn, x)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mloss_fn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     ) -> Tuple[ep.Tensor, ep.Tensor]:\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\Arthur\\anaconda3\\envs\\saliency\\lib\\site-packages\\eagerpy\\framework.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(f, t, *args, **kwargs)\u001b[0m\n\u001b[0;32m    357\u001b[0m def value_and_grad(\n\u001b[0;32m    358\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m ) -> Tuple[TensorType, TensorType]:\n\u001b[1;32m--> 360\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\Arthur\\anaconda3\\envs\\saliency\\lib\\site-packages\\eagerpy\\tensor\\tensor.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m     def value_and_grad(\n\u001b[0;32m    551\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     ) -> Tuple[TensorType, TensorType]:\n\u001b[1;32m--> 553\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_and_grad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\Arthur\\anaconda3\\envs\\saliency\\lib\\site-packages\\eagerpy\\tensor\\tensorflow.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    478\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m             \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTensorFlowTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mx_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Arthur\\anaconda3\\envs\\saliency\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1059\u001b[0m               output_gradients))\n\u001b[0;32m   1060\u001b[0m       output_gradients = [None if x is None else ops.convert_to_tensor(x)\n\u001b[0;32m   1061\u001b[0m                           for x in output_gradients]\n\u001b[0;32m   1062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1064\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[0mflat_sources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Arthur\\anaconda3\\envs\\saliency\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     raise ValueError(\n\u001b[0;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m       \u001b[0msources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Arthur\\anaconda3\\envs\\saliency\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"gradient_tape/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Arthur\\anaconda3\\envs\\saliency\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(op, *grad)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRegisterGradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"FusedBatchNormV3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_FusedBatchNormV3Grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_BaseFusedBatchNormGrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\Arthur\\anaconda3\\envs\\saliency\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(op, version, *grad)\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[1;34m\"is_training\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m     }\n\u001b[0;32m    904\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"reserve_space_3\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 906\u001b[1;33m     \u001b[0mdx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    907\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"NCHW\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m       \u001b[0mdx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"NCDHW\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Arthur\\anaconda3\\envs\\saliency\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(y_backprop, x, scale, reserve_space_1, reserve_space_2, reserve_space_3, epsilon, data_format, is_training, name)\u001b[0m\n\u001b[0;32m   5102\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5103\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5104\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5105\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5106\u001b[1;33m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5107\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5108\u001b[0m       return fused_batch_norm_grad_v3_eager_fallback(\n\u001b[0;32m   5109\u001b[0m           \u001b[0my_backprop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreserve_space_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreserve_space_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for model_name in models_availables:\n",
        "    model = load_model(model_name)\n",
        "    saliency = get_saliency_object(model)\n",
        "    for attack_name in attacks_availables:\n",
        "        for attack_rate in epsilons:\n",
        "            image_index = 0\n",
        "            for filename in os.listdir(input_directory):\n",
        "                filepath = os.path.join(input_directory, filename)\n",
        "                if os.path.isfile(filepath):\n",
        "\n",
        "                    original_image = get_image(filepath, model_name)\n",
        "                    print(\"Executing : Saliency\")\n",
        "                    saliency_image = saliency(score_list[image_index], original_image)[0]\n",
        "\n",
        "\n",
        "                    print(\"Executing : Attack \" + attack_name)\n",
        "                    attacked_image=\"\"\n",
        "                    if attack_name==attacks_availables[0]:\n",
        "                        attacked_image = get_attacked_image_PGD(model, orig_input=original_image, attack_rate=attack_rate)\n",
        "                    elif attack_name==\"FGSM\":\n",
        "                        attacked_image = get_attacked_image_FGSM(image=original_image,image_index=index_images_model[image_index] , model=model, attack_rate=attack_rate)\n",
        "                    \n",
        "                    print(\"Executing : Saliency on Attacked image\")\n",
        "                    attacked_image_array_preprocessed = preprocess_image(np.array(attacked_image).astype(np.float32), model_name)\n",
        "                    attacked_saliency_image = saliency(score_list[image_index], attacked_image_array_preprocessed)[0]\n",
        "\n",
        "                    print(\"Executing : Prediction attacked image\")\n",
        "                    img_attacked_to_predict = np.resize(attacked_image_array_preprocessed, (1, 224, 224, 3))\n",
        "                    predictions_attacked = model.predict(img_attacked_to_predict)\n",
        "                    prediction_attacked = round(predictions_attacked[0][index_images_model[image_index]]*1000000)\n",
        "\n",
        "                    original_image = cv2.imread(filepath)\n",
        "                    img_original_to_predict = np.resize(original_image, (1, 224, 224, 3))\n",
        "                    predictions_original = model.predict(img_original_to_predict)\n",
        "                    prediction_original = round(predictions_original[0][index_images_model[image_index]]*1000000)\n",
        "\n",
        "                    filename_output = filename[0:-4] + \"_\" + model_name + \"_\" + attack_name + \"_\" + str(attack_rate)\n",
        "\n",
        "\n",
        "                    print(\"Executing : Save images\")\n",
        "                    save_original_image = np.array(original_image)\n",
        "                    save_attacked_image = np.array(attacked_image)\n",
        "                    save_saliency_image = 255*np.array(saliency_image)\n",
        "                    save_attacked_saliency_image = 255*np.array(attacked_saliency_image)\n",
        "                    cv2.imwrite(output_directory + filename_output + \"_\" + str(prediction_original) + \"_nosaliency_noattacked\" + \".png\", save_original_image)\n",
        "                    cv2.imwrite(output_directory + filename_output + \"_\" + str(prediction_attacked) + \"_nosaliency_attacked\"   + \".png\", save_attacked_image)\n",
        "                    cv2.imwrite(output_directory + filename_output + \"_\" + \"-1\"                     + \"_saliency_noattacked\"   + \".png\", save_saliency_image)\n",
        "                    cv2.imwrite(output_directory + filename_output + \"_\" + \"-1\"                     + \"_saliency_attacked\"     + \".png\", save_attacked_saliency_image)\n",
        "                    \n",
        "                    image_index+=1\n",
        "                    print(\"-----------------------------------------------------------------------------------------------------\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
