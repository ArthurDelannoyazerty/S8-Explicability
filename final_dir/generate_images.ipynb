{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# A script that generate images in the output folder : non attacked, saliency non attacked, attacked, saliency attacked (with all combinaisons of : models, attacks, effect of attack)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_J17H9FPoiVW"
      },
      "outputs": [],
      "source": [
        "#!pip install tf-keras-vis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "nYcwSbqeorX6",
        "outputId": "42d3c6f9-51fc-421a-bb4f-d03362b8e296"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing : Load libraries\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow recognized 0 GPUs\n"
          ]
        }
      ],
      "source": [
        "print(\"Executing : Load libraries\")\n",
        "\n",
        "import os\n",
        "# uncomment to force the non use of GPU\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tf_keras_vis.utils import num_of_gpus\n",
        "\n",
        "from keras.utils import load_img, img_to_array, array_to_img\n",
        "\n",
        "import foolbox as fb\n",
        "from foolbox.criteria import TargetedMisclassification\n",
        "from foolbox.attacks import PGD\n",
        "\n",
        "from keras.applications.resnet import ResNet50, preprocess_input, decode_predictions\n",
        "\n",
        "from tf_keras_vis.utils.scores import CategoricalScore\n",
        "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
        "from tf_keras_vis.saliency import Saliency\n",
        "\n",
        "from PIL import Image, ImageChops, ImageEnhance\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from scipy.stats import pearsonr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "_, gpus = num_of_gpus()\n",
        "print('Tensorflow recognized {} GPUs'.format(gpus))\n",
        "\n",
        "path_project_root = os.path.dirname(os.path.abspath(''))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YmybNIO7oztN"
      },
      "source": [
        "# SALIENCY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O1jT7hhgou_o"
      },
      "outputs": [],
      "source": [
        "def load_model(model_name=\"MobileNetV2\"):\n",
        "    \"\"\"\n",
        "        Return the selected model. Argument : name of the model.\n",
        "    \"\"\"\n",
        "    print(\"Executing : Load Model\")\n",
        "    model=\"\"\n",
        "    if model_name==\"VGG16\":\n",
        "        from keras.applications.vgg16 import VGG16 as Model\n",
        "        model = Model(weights='imagenet', include_top=True)\n",
        "    elif model_name==\"MobileNetV2\":\n",
        "        from keras.applications.mobilenet_v2 import MobileNetV2 as Model\n",
        "        model = Model(weights='imagenet', include_top=True)\n",
        "    elif model_name==\"ResNet152V2\":\n",
        "        from keras.applications.resnet_v2 import ResNet152V2 as Model\n",
        "        model = Model(weights='imagenet', include_top=True)\n",
        "    else:\n",
        "        print(\"Error : model not available\")\n",
        "        raise NameError()\n",
        "    return model\n",
        "\n",
        "def get_image(path, size=(224,224), model_name=\"MobileNetV2\"):\n",
        "    print(\"Executing : Load And Preprocess Image\")\n",
        "    image= load_img(path)\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = preprocess_image(image, model_name)\n",
        "    return image\n",
        "\n",
        "def preprocess_image(image, model_name):\n",
        "    if model_name==\"VGG16\":\n",
        "        image = tf.keras.applications.vgg16.preprocess_input(image)\n",
        "    elif model_name==\"MobileNetV2\":\n",
        "        image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
        "    elif model_name==\"MobileNetV2\":\n",
        "        image = tf.keras.applications.resnet_v2.preprocess_input(image)\n",
        "    return image\n",
        "\n",
        "def get_score_function(index_list):\n",
        "    print(\"Executing : Create Score Function\")\n",
        "    return CategoricalScore(index_list)\n",
        "\n",
        "def get_saliency_object(model):\n",
        "    print(\"Executing : Create Saliency Object\")\n",
        "    replace2linear = ReplaceToLinear()\n",
        "    saliency = Saliency(model, model_modifier=replace2linear, clone=True)\n",
        "    return saliency"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ejZM-CzPo_Ok"
      },
      "source": [
        "# ATTACK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fdkXUR9nowpL"
      },
      "outputs": [],
      "source": [
        "def get_attacked_image_FGSM(image, image_index, model, debug = False, preprocessinput = False, attack_rate = 15): #attack_rate entre 0 et 100\n",
        "\n",
        "    pretrained_model = model\n",
        "    pretrained_model.trainable = False\n",
        "\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    image = image[None, ...]\n",
        "\n",
        "    image_probs = pretrained_model.predict(image)\n",
        "    \n",
        "    if debug:\n",
        "      decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions\n",
        "      _, image_class, class_confidence = decode_predictions(image_probs, top=1)[0][0]\n",
        "      plt.imshow(image[0] * 0.5 + 0.5)  # To change [-1, 1] to [0,1]\n",
        "      plt.title('{} : {:.2f}% Confidence'.format(image_class, class_confidence*100))\n",
        "      plt.show()\n",
        "\n",
        "    loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "    label = tf.one_hot(image_index, image_probs.shape[-1])\n",
        "    label = tf.reshape(label, (1, image_probs.shape[-1]))\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      tape.watch(image)\n",
        "      prediction = pretrained_model(image)\n",
        "      loss = loss_object(label, prediction)\n",
        "\n",
        "    # Get the gradients of the loss w.r.t to the input image.\n",
        "    gradient = tape.gradient(loss, image)\n",
        "    # Get the sign of the gradients to create the perturbation\n",
        "    signed_grad = tf.sign(gradient)\n",
        "    perturbations = signed_grad\n",
        "    if debug :\n",
        "      plt.imshow(perturbations[0] * 0.5 + 0.5);  # To change [-1, 1] to [0,1]\n",
        "      plt.title(\"Noise\")\n",
        "      plt.show()\n",
        "\n",
        "    #epsilons = [0, 0.01, 0.1, 0.15] #noter \"taux d'attaque\"\n",
        "    descriptions = ['Epsilon = {:0.3f}'.format(attack_rate)]\n",
        "    \n",
        "    #for i, eps in enumerate(epsilons):\n",
        "    adv_x = image + (attack_rate/100)*perturbations\n",
        "    adv_x = tf.clip_by_value(adv_x, -1, 1)\n",
        "    \n",
        "    if debug :\n",
        "      _, label, confidence = decode_predictions(pretrained_model.predict(adv_x), top=1)[0][0]\n",
        "      plt.imshow(adv_x[0]*0.5+0.5)\n",
        "      plt.title('{} \\n {} : {:.2f}% Confidence'.format(descriptions[0], label, confidence*100))\n",
        "      plt.show()\n",
        "\n",
        "    attacked_image = adv_x[0]\n",
        "    return attacked_image\n",
        "\n",
        "def get_attacked_image_PGD(model, orig_input, debug = False, attack_rate = 10, class_target = 999) : #class_target c'est la classe que l'on cherche à appliquer\n",
        "    \n",
        "    orig_input = tf.expand_dims(orig_input, 0)\n",
        "    \n",
        "    fmodel = fb.TensorFlowModel(model, bounds=(-255, 255))\n",
        "\n",
        "   \n",
        "    #goldfish = 1; brown bear = 294; assault rifle = 413 #class de notre image\n",
        "    # 2 = great white shark #classe que l'on cherche à obtenir\n",
        "    adv_label = tf.convert_to_tensor([class_target])\n",
        "\n",
        "    criterion = TargetedMisclassification(adv_label)\n",
        "\n",
        "\n",
        "    attack = PGD()\n",
        "    input_as_tensor = tf.convert_to_tensor(orig_input)\n",
        "    adv_input = attack.run(fmodel, input_as_tensor, criterion, epsilon=attack_rate)\n",
        "\n",
        "    adv_img = (adv_input.numpy() + 255) / 2\n",
        "    adv_img = adv_img.reshape(224, 224, 3)\n",
        "    adv_img = array_to_img(adv_img)\n",
        "    b, g, r = adv_img.split()\n",
        "    adv_img = Image.merge(\"RGB\", (r, g, b))\n",
        "\n",
        "    adv_input = img_to_array(adv_img)\n",
        "    adv_input = adv_input.reshape((1, 224, 224, 3))\n",
        "    adv_input = preprocess_input(adv_input)\n",
        "    predictions = model.predict(adv_input)\n",
        "    \n",
        "    if debug :\n",
        "      labels = decode_predictions(predictions)\n",
        "      kind = labels[0][0][1].replace(\"_\", \" \").title()\n",
        "      percent = round(labels[0][0][2] * 100, 2)\n",
        "      print(f\"This is a {kind}. I am {percent} % sure.\")\n",
        "      print()\n",
        "      print(\"Other suggestions:\")\n",
        "      for i in range(4):\n",
        "        kind = labels[0][i+1][1].replace(\"_\", \" \").title()\n",
        "        percent = round(labels[0][i+1][2] * 100, 2)\n",
        "        print(f\"{kind}: {percent} %\")\n",
        "      difference = ImageChops.difference(adv_img, orig_input)\n",
        "      plt.figure()\n",
        "      plt.imshow(np.array(difference))\n",
        "      plt.show()\n",
        "      difference = ImageEnhance.Brightness(difference).enhance(10)\n",
        "      plt.figure()\n",
        "      plt.imshow(np.array(difference))\n",
        "      plt.show()\n",
        "\n",
        "    return adv_img"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2LfLYblzpAnG"
      },
      "source": [
        "# Metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EfurSXi7oyXw"
      },
      "outputs": [],
      "source": [
        "# Ouvrir les cartes de saillance\n",
        "def img_open(path_sal_map,path_attacked_sal_map):\n",
        "    img1 = cv2.imread(path_sal_map)\n",
        "    img2 = cv2.imread(path_attacked_sal_map)\n",
        "    return img1,img2\n",
        "\n",
        "# Calcul de la différence absolue\n",
        "# Plus la valeur est proche de 0 plus les images sont similaires\n",
        "def diff_abs(path_sal_map,path_attacked_sal_map):\n",
        "    img1 = cv2.imread(path_sal_map)\n",
        "    img2 = cv2.imread(path_attacked_sal_map)\n",
        "    return np.sum(np.abs(img1 - img2))\n",
        "\n",
        "# Calcul de la différence quadratique (mse)\n",
        "# Plus la valeur est proche de 0 plus les images sont similaires\n",
        "def diff_quadratique(path_sal_map,path_attacked_sal_map):\n",
        "    img1, img2 = img_open(path_sal_map,path_attacked_sal_map)\n",
        "    return np.sum(np.square(img1 - img2))\n",
        "\n",
        "# Calcul du coef de corrélation\n",
        "# Plus la valeur est proche de 1 plus les images sont similaires\n",
        "def coef_correlation(path_sal_map,path_attacked_sal_map):\n",
        "    img1, img2 = img_open(path_sal_map,path_attacked_sal_map)\n",
        "    result = pearsonr(img1.flatten(),img2.flatten())\n",
        "    return result.statistic\n",
        "\n",
        "# Calcul du ssim Structural Similarity Index\n",
        "# Plus la valeur est proche de 1 plus les images sont similaires\n",
        "def ssim_func(path_sal_map,path_attacked_sal_map):\n",
        "    img1 = cv2.imread(path_sal_map)\n",
        "    img2 = cv2.imread(path_attacked_sal_map)\n",
        "    gray_img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "    gray_img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "    valssim = ssim(gray_img1, gray_img2)\n",
        "    return valssim\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FrLezdjTpESi"
      },
      "source": [
        "# MAIN PROGRAM"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If 1 image is 100Ko => 40Mo generated for each input image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing : Load Model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing : Create Saliency Object\n",
            "Executing : Create Score Function\n",
            "Executing : Load And Preprocess Image\n",
            "WARNING:tensorflow:From c:\\Users\\ahdel\\anaconda3\\envs\\saliency\\lib\\site-packages\\foolbox\\models\\tensorflow.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "'Image' object is not subscriptable",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39melif\u001b[39;00m attack_name\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFGSM\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     27\u001b[0m     attacked_image \u001b[39m=\u001b[39m get_attacked_image_FGSM(image\u001b[39m=\u001b[39moriginal_image, image_index\u001b[39m=\u001b[39mimage_index, model\u001b[39m=\u001b[39mmodel, attack_rate\u001b[39m=\u001b[39mattack_rate)\n\u001b[1;32m---> 29\u001b[0m attacked_saliency_image \u001b[39m=\u001b[39m preprocess_image(attacked_image, model_name)\n\u001b[0;32m     30\u001b[0m attacked_saliency_image \u001b[39m=\u001b[39m saliency(score, attacked_saliency_image)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     32\u001b[0m original_image_array \u001b[39m=\u001b[39m (np\u001b[39m.\u001b[39marray(original_image)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\n",
            "Cell \u001b[1;32mIn[3], line 30\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[1;34m(image, model_name)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_image\u001b[39m(image, model_name):\n\u001b[0;32m     29\u001b[0m     \u001b[39mif\u001b[39;00m model_name\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mVGG16\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 30\u001b[0m         image \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mapplications\u001b[39m.\u001b[39;49mvgg16\u001b[39m.\u001b[39;49mpreprocess_input(image)\n\u001b[0;32m     31\u001b[0m     \u001b[39melif\u001b[39;00m model_name\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMobileNetV2\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     32\u001b[0m         image \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mapplications\u001b[39m.\u001b[39mmobilenet_v2\u001b[39m.\u001b[39mpreprocess_input(image)\n",
            "File \u001b[1;32mc:\\Users\\ahdel\\anaconda3\\envs\\saliency\\lib\\site-packages\\keras\\applications\\vgg16.py:257\u001b[0m, in \u001b[0;36mpreprocess_input\u001b[1;34m(x, data_format)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkeras.applications.vgg16.preprocess_input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    256\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_input\u001b[39m(x, data_format\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 257\u001b[0m     \u001b[39mreturn\u001b[39;00m imagenet_utils\u001b[39m.\u001b[39;49mpreprocess_input(\n\u001b[0;32m    258\u001b[0m         x, data_format\u001b[39m=\u001b[39;49mdata_format, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcaffe\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m    259\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\ahdel\\anaconda3\\envs\\saliency\\lib\\site-packages\\keras\\applications\\imagenet_utils.py:123\u001b[0m, in \u001b[0;36mpreprocess_input\u001b[1;34m(x, data_format, mode)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m _preprocess_numpy_input(x, data_format\u001b[39m=\u001b[39mdata_format, mode\u001b[39m=\u001b[39mmode)\n\u001b[0;32m    122\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m _preprocess_symbolic_input(x, data_format\u001b[39m=\u001b[39;49mdata_format, mode\u001b[39m=\u001b[39;49mmode)\n",
            "File \u001b[1;32mc:\\Users\\ahdel\\anaconda3\\envs\\saliency\\lib\\site-packages\\keras\\applications\\imagenet_utils.py:287\u001b[0m, in \u001b[0;36m_preprocess_symbolic_input\u001b[1;34m(x, data_format, mode)\u001b[0m\n\u001b[0;32m    284\u001b[0m         x \u001b[39m=\u001b[39m x[:, ::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]\n\u001b[0;32m    285\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    286\u001b[0m     \u001b[39m# 'RGB'->'BGR'\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     x \u001b[39m=\u001b[39m x[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, ::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\n\u001b[0;32m    288\u001b[0m mean \u001b[39m=\u001b[39m [\u001b[39m103.939\u001b[39m, \u001b[39m116.779\u001b[39m, \u001b[39m123.68\u001b[39m]\n\u001b[0;32m    289\u001b[0m std \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[1;31mTypeError\u001b[0m: 'Image' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "models_availables = [ \"VGG16\", \"ResNet152V2\"]#\"MobileNetV2\",\n",
        "attacks_availables = [\"FGSM\", \"PGD\"]\n",
        "input_directory  = os.path.join(path_project_root, 'final_dir\\images\\input')\n",
        "output_directory = os.path.join(path_project_root, 'final_dir\\images\\output\\\\')\n",
        "index_images_model = [404, 294, 500, 1, 576, 587, 606, 413]\n",
        "\n",
        "for model_name in models_availables:\n",
        "    model = load_model(model_name)\n",
        "    saliency = get_saliency_object(model)\n",
        "    for attack_name in attacks_availables:\n",
        "        for attack_rate in range(2, 100, 2):\n",
        "            for filename in os.listdir(input_directory):\n",
        "                image_index = 0\n",
        "                filepath = os.path.join(input_directory, filename)\n",
        "                if os.path.isfile(filepath):\n",
        "                    filename_output = filename[0:-4] + \"_\" + model_name + \"_\" + attack_name + \"_\" + str(attack_rate)\n",
        "\n",
        "                    score = get_score_function([index_images_model[image_index]])\n",
        "\n",
        "                    original_image = get_image(filepath, model_name)\n",
        "                    saliency_image = saliency(score, original_image)[0]\n",
        "\n",
        "                    attacked_image=\"\"\n",
        "                    if attack_name==attacks_availables[0]:\n",
        "                        attacked_image = get_attacked_image_PGD(model, orig_input=original_image, attack_rate=attack_rate)\n",
        "                    elif attack_name==\"FGSM\":\n",
        "                        attacked_image = get_attacked_image_FGSM(image=original_image, image_index=image_index, model=model, attack_rate=attack_rate)\n",
        "                    \n",
        "                    attacked_saliency_image = preprocess_image(attacked_image, model_name)\n",
        "                    attacked_saliency_image = saliency(score, attacked_saliency_image)[0]\n",
        "\n",
        "                    original_image_array = (np.array(original_image)+1)/2\n",
        "                    plt.imsave(output_directory + filename_output + \"_nosaliency_noattacked\" + \".png\", original_image_array)\n",
        "                    plt.imsave(output_directory + filename_output + \"_saliency_noattacked\"   + \".png\", saliency_image)\n",
        "                    plt.imsave(output_directory + filename_output + \"_nosaliency_attacked\"   + \".png\", attacked_image)\n",
        "                    plt.imsave(output_directory + filename_output + \"_saliency_attacked\"     + \".png\", attacked_saliency_image)\n",
        "                    \n",
        "                    image_index+=1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
