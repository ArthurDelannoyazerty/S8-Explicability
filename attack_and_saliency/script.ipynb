{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J17H9FPoiVW",
        "outputId": "c3e9f8b5-5184-4461-8b82-74871e899a76"
      },
      "outputs": [],
      "source": [
        "#!pip install tf-keras-vis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYcwSbqeorX6",
        "outputId": "412f1664-5ae9-46b0-f780-e8619be5e506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing : Load libraries\n",
            "Tensorflow recognized 0 GPUs\n"
          ]
        }
      ],
      "source": [
        "print(\"Executing : Load libraries\")\n",
        "\n",
        "import os\n",
        "# uncomment to force the non use of GPU\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tf_keras_vis.utils import num_of_gpus\n",
        "\n",
        "from keras.utils import load_img\n",
        "\n",
        "from tf_keras_vis.utils.scores import CategoricalScore\n",
        "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
        "from tf_keras_vis.saliency import Saliency\n",
        "\n",
        "_, gpus = num_of_gpus()\n",
        "print('Tensorflow recognized {} GPUs'.format(gpus))\n",
        "\n",
        "output_folder = \"attack_and_saliency/images/output/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmybNIO7oztN"
      },
      "source": [
        "# SALIENCY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O1jT7hhgou_o"
      },
      "outputs": [],
      "source": [
        "def load_model(model_name=\"MobileNetV2\"):\n",
        "    \"\"\"\n",
        "        Return the selected model. Argument : name of the model.\n",
        "    \"\"\"\n",
        "    print(\"Executing : Load Model\")\n",
        "    model=\"\"\n",
        "    if model_name==\"VGG16\":\n",
        "        from keras.applications.vgg16 import VGG16 as Model\n",
        "        model = Model(weights='imagenet', include_top=True)\n",
        "    elif model_name==\"MobileNetV2\":\n",
        "        from keras.applications.mobilenet_v2 import MobileNetV2 as Model\n",
        "        model = Model(weights='imagenet', include_top=True)\n",
        "    else:\n",
        "        print(\"Error : model not available\")\n",
        "        raise NameError()\n",
        "    return model\n",
        "\n",
        "def get_image(path, size=(224,224), model_name=\"MobileNetV2\"):\n",
        "    print(\"Executing : Load And Preprocess Image\")\n",
        "    image= load_img(path, target_size=size)\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    if model_name==\"VGG16\":\n",
        "        image = tf.keras.applications.vgg16.preprocess_input(image)\n",
        "    elif model_name==\"MobileNetV2\":\n",
        "        image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
        "    return image\n",
        "\n",
        "def get_score_function(index_list):\n",
        "    print(\"Executing : Create Score Function\")\n",
        "    return CategoricalScore(index_list)\n",
        "\n",
        "def get_saliency_object(model):\n",
        "    print(\"Executing : Create Saliency Object\")\n",
        "    replace2linear = ReplaceToLinear()\n",
        "    saliency = Saliency(model, model_modifier=replace2linear, clone=True)\n",
        "    return saliency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejZM-CzPo_Ok"
      },
      "source": [
        "# ATTACK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fdkXUR9nowpL"
      },
      "outputs": [],
      "source": [
        "def get_attacked_image(image):\n",
        "    #TODO \n",
        "    attacked_image = 0*image \n",
        "    return attacked_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LfLYblzpAnG"
      },
      "source": [
        "# Metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EfurSXi7oyXw"
      },
      "outputs": [],
      "source": [
        "def get_score_metric_difference(image, attacked_image):\n",
        "    #TODO \n",
        "    difference = abs(image - attacked_image)\n",
        "    score_metric = sum(difference)\n",
        "    return score_metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrLezdjTpESi"
      },
      "source": [
        "# MAIN PROGRAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "EC2hhDhHpIsv",
        "outputId": "e4077673-b1f0-440e-f515-ddcbeae8b248"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing : Load Model\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "Unable to open file (truncated file: eof = 6111232, sblock->base_addr = 0, stored_eof = 14536120)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m index_model \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m]\n\u001b[0;32m      3\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39madversarial\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m\\\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mPGD\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mgoldfishPGD.png\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m model \u001b[39m=\u001b[39m load_model(\u001b[39m\"\u001b[39;49m\u001b[39mMobileNetV2\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m image \u001b[39m=\u001b[39m get_image(path, model_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMobileNetV2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m score \u001b[39m=\u001b[39m get_score_function(index_model)\n",
            "Cell \u001b[1;32mIn[3], line 12\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(model_name)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39melif\u001b[39;00m model_name\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMobileNetV2\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     11\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmobilenet_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m MobileNetV2 \u001b[39mas\u001b[39;00m Model\n\u001b[1;32m---> 12\u001b[0m     model \u001b[39m=\u001b[39m Model(weights\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mimagenet\u001b[39;49m\u001b[39m'\u001b[39;49m, include_top\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     13\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mError : model not available\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\ahdel\\anaconda3\\envs\\keras-vis\\lib\\site-packages\\keras\\applications\\mobilenet_v2.py:481\u001b[0m, in \u001b[0;36mMobileNetV2\u001b[1;34m(input_shape, alpha, include_top, weights, input_tensor, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    477\u001b[0m         weight_path \u001b[39m=\u001b[39m BASE_WEIGHT_PATH \u001b[39m+\u001b[39m model_name\n\u001b[0;32m    478\u001b[0m         weights_path \u001b[39m=\u001b[39m data_utils\u001b[39m.\u001b[39mget_file(\n\u001b[0;32m    479\u001b[0m             model_name, weight_path, cache_subdir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    480\u001b[0m         )\n\u001b[1;32m--> 481\u001b[0m     model\u001b[39m.\u001b[39;49mload_weights(weights_path)\n\u001b[0;32m    482\u001b[0m \u001b[39melif\u001b[39;00m weights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    483\u001b[0m     model\u001b[39m.\u001b[39mload_weights(weights)\n",
            "File \u001b[1;32mc:\\Users\\ahdel\\anaconda3\\envs\\keras-vis\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\ahdel\\anaconda3\\envs\\keras-vis\\lib\\site-packages\\h5py\\_hl\\files.py:567\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    558\u001b[0m     fapl \u001b[39m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    559\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    560\u001b[0m                      alignment_threshold\u001b[39m=\u001b[39malignment_threshold,\n\u001b[0;32m    561\u001b[0m                      alignment_interval\u001b[39m=\u001b[39malignment_interval,\n\u001b[0;32m    562\u001b[0m                      meta_block_size\u001b[39m=\u001b[39mmeta_block_size,\n\u001b[0;32m    563\u001b[0m                      \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    564\u001b[0m     fcpl \u001b[39m=\u001b[39m make_fcpl(track_order\u001b[39m=\u001b[39mtrack_order, fs_strategy\u001b[39m=\u001b[39mfs_strategy,\n\u001b[0;32m    565\u001b[0m                      fs_persist\u001b[39m=\u001b[39mfs_persist, fs_threshold\u001b[39m=\u001b[39mfs_threshold,\n\u001b[0;32m    566\u001b[0m                      fs_page_size\u001b[39m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 567\u001b[0m     fid \u001b[39m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[39m=\u001b[39mswmr)\n\u001b[0;32m    569\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(libver, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    570\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_libver \u001b[39m=\u001b[39m libver\n",
            "File \u001b[1;32mc:\\Users\\ahdel\\anaconda3\\envs\\keras-vis\\lib\\site-packages\\h5py\\_hl\\files.py:231\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m swmr \u001b[39mand\u001b[39;00m swmr_support:\n\u001b[0;32m    230\u001b[0m         flags \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 231\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39;49mopen(name, flags, fapl\u001b[39m=\u001b[39;49mfapl)\n\u001b[0;32m    232\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    233\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mopen(name, h5f\u001b[39m.\u001b[39mACC_RDWR, fapl\u001b[39m=\u001b[39mfapl)\n",
            "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mh5py\\h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mOSError\u001b[0m: Unable to open file (truncated file: eof = 6111232, sblock->base_addr = 0, stored_eof = 14536120)"
          ]
        }
      ],
      "source": [
        "image_title = 'Goldfish'\n",
        "index_model = [1]\n",
        "path = \"adversarial\\images\\output\\PGD\\goldfishPGD.png\"\n",
        "\n",
        "model = load_model(\"MobileNetV2\")\n",
        "image = get_image(path, model_name=\"MobileNetV2\")\n",
        "score = get_score_function(index_model)\n",
        "saliency = get_saliency_object(model)\n",
        "\n",
        "print(\"Executing : Calculating Saliency Image\")\n",
        "saliency_image = saliency(score, image)[0]\n",
        "print(\"Executing : Calculating Smooth Saliency Image\")\n",
        "smooth_saliency_image = saliency(score, image, smooth_samples=20, smooth_noise=0.20)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vHRWw52pMhB"
      },
      "source": [
        "## Attack image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0JjAt6QpKqO"
      },
      "outputs": [],
      "source": [
        "attacked_image = get_attacked_image(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za3EF5qJpPdK"
      },
      "source": [
        "## Saliency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOZvKN7NpSyZ"
      },
      "outputs": [],
      "source": [
        "print(\"Executing : Calculating Saliency Image\")\n",
        "saliency_attacked_image = saliency(score, image)[0]\n",
        "print(\"Executing : Calculating Smooth Saliency Image\")\n",
        "smooth_saliency_attacked_image = saliency(score, image, smooth_samples=20, smooth_noise=0.20)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AHXsBeKpVBB"
      },
      "source": [
        "## Metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AcuPzV1oe-M"
      },
      "outputs": [],
      "source": [
        "score_metric_classic_saliency = get_score_metric_difference(saliency_image, saliency_attacked_image)\n",
        "score_metric_smooth_saliency  = get_score_metric_difference(smooth_saliency_image, smooth_saliency_attacked_image)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
